# Default values for refinery.

## Scaling Refinery ##
#
# Refinery is a stateful service and is not optimized for dynamic auto-scaling.
# Changes in cluster membership can result in temporary inconsistent sampling
# decisions and dropped traces. As such, we recommend provisioning refinery for
# your anticipated peak load
#

# Use replicaCount and resource limits to set the size of your Refinery cluster
# per your anticipated peak load.
# replicaCount is ignored if autoscaling is enabled
replicaCount: 3

# Changing memory limits from the default 2Gi, requires updates to the
# config.InMemCollector.MaxAlloc property.
resources:
  limits:
    cpu: 2000m
    # Changing memory limits requires updating config.InMemCollector.MaxAlloc
    memory: 2Gi
  requests:
    cpu: 500m
    memory: 500Mi

image:
  repository: honeycombio/refinery
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets: [ ]
nameOverride: ""
fullnameOverride: ""

# Use to pass in additional environment variables into Refinery
# Refinery supports environment variables for some configuration options such as:
# - Honeycomb API Key used by Logger and Metrics: REFINERY_HONEYCOMB_API_KEY
# - Redis Host: REFINERY_REDIS_HOST
# - Redis Password: REFINERY_REDIS_PASSWORD
environment: [ ]
  # - name: REFINERY_HONEYCOMB_API_KEY
  #   valueFrom:
  #     secretKeyRef:
  #       name: honeycomb
  #       key: api-key

# Values used to build config.yaml.
# See the example in sample-configs/config_complete.yaml for full details on all properties
config:
  # ListenAddr is the IP and port on which to listen for incoming events.
  ListenAddr: 0.0.0.0:8080

  # GRPCListenAddr is the IP and port on which to listen for incoming events over gRPC.
  GRPCListenAddr: 0.0.0.0:4317

  # PeerListenAddr is the IP and port on which to listen for traffic being rerouted from a peer.
  PeerListenAddr: 0.0.0.0:8081

  # HoneycombAPI is the URL for the upstream Honeycomb API
  HoneycombAPI: https://api.honeycomb.io

  # LoggingLevel valid options are "debug", "info", "error", and "panic".
  LoggingLevel: info

  # SendDelay is a short timer that will be triggered when a trace is complete.
  # Refinery will wait this duration before actually sending the trace.  The
  # reason for this short delay is to allow for small network delays or clock
  # jitters to elapse and any final spans to arrive before actually sending the
  # trace.  This supports duration strings with supplied units. Set to 0 for
  # immediate sends.
  SendDelay: 2s

  # TraceTimeout is a long timer; it represents the outside boundary of how long
  # to wait before sending an incomplete trace. Normally traces are sent when the
  # root span arrives. Sometimes the root span never arrives (due to crashes or
  # whatever), and this timer will send a trace even without having received the
  # root span. If you have particularly long-lived traces you should increase this
  # timer. This supports duration strings with supplied units.
  TraceTimeout: 60s

  # MaxBatchSize is the number of events to be included in the batch for sending
  MaxBatchSize: 500

  # SendTicker is a short timer; it determines the duration to use to check for traces to send
  SendTicker: 100ms

  # UpstreamBufferSize and PeerBufferSize control how large of an event queue to use
  # when buffering events that will be forwarded to peers or the upstream API.
  UpstreamBufferSize: 1000
  PeerBufferSize: 1000

  # Configure how Refinery peers are discovered and managed
  PeerManagement:
    # The type should always be redis when deployed to Kubernetes environments
    Type: "redis"

    # RedisHost is used to connect to redis for peer cluster membership management.
    # Further, if the environment variable 'REFINERY_REDIS_HOST' is set it takes
    # precedence and this value is ignored.
    # Not eligible for live reload.
    RedisHost: "refinery-redis:6379"

    # RedisPassword is the password used to connect to redis for peer cluster membership management.
    # If the environment variable 'REFINERY_REDIS_PASSWORD' is set it takes
    # precedence and this value is ignored.
    # Not eligible for live reload.
    RedisPassword: ""

    # UseTLS enables TLS when connecting to redis for peer cluster membership management, and sets the MinVersion to 1.2.
    # Not eligible for live reload.
    UseTLS: false

    # IdentifierInterfaceName is optional.
    # Due to the nature of DNS in Kubernetes, it is recommended to set this value to the 'eth0' interface name.
    # When configured the pod's IP will be used in the peer list
    IdentifierInterfaceName: eth0

    # UseIPV6Identifier is optional. If using IdentifierInterfaceName, Refinery will default to the first
    # IPv4 unicast address it finds for the specified interface. If UseIPV6Identifier is used, will use
    # the first IPV6 unicast address found.
    UseIPV6Identifier: false

  # InMemCollector brings together all the settings that are relevant to
  # collecting spans together to make traces.
  InMemCollector:

    # The collection cache is used to collect all spans into a trace as well as
    # remember the sampling decision for any spans that might come in after the
    # trace has been marked "complete" (either by timing out or seeing the root
    # span). The number of traces in the cache should be many multiples (100x to
    # 1000x) of the total number of concurrently active traces (trace throughput *
    # trace duration).
    CacheCapacity: 1000

    # MaxAlloc is optional. If set, it must be an integer >= 0.
    # If set to a non-zero value, once per tick (see SendTicker) the collector
    # will compare total allocated bytes to this value. If allocation is too
    # high, cache capacity will be reduced and an error will be logged.
    # Useful values for this setting are generally in the range of 75%-90% of
    # available system memory. Using 80% is the recommended.
    # This value should be set in according to the resources.limits.memory
    # By default that setting is 2GB, and this is set to 85% of that limit
    # 2 * 1024 * 1024 * 1024 * 0.80 = 1,717,986,918
    MaxAlloc: 1717986918

  # Logger describes which logger to use for Refinery logs. Valid options are
  # "logrus" and "honeycomb". The logrus option will write logs to STDOUT and the
  # honeycomb option will send them to a Honeycomb dataset.
  Logger: logrus

  # Metrics describes which service to use for Refinery metrics. Valid options are
  # "prometheus" and "honeycomb". The prometheus option starts a listener that
  # will reply to a request for /metrics. The honeycomb option will send summary
  # metrics to a Honeycomb dataset.
  Metrics: prometheus

  # If using the Honeycomb Logger or Metrics, you can specify the API Key using an environment variable instead.
  #
  # HoneycombLogger is a section of the config only used if you are using the
  # HoneycombLogger to send all logs to a Honeycomb Dataset. If you are using a
  # different logger (eg file-based logger) you can leave all this commented out.
  # HoneycombLogger:

    # LoggerHoneycombAPI is the URL for the upstream Honeycomb API.
    # LoggerHoneycombAPI: https://api.honeycomb.io

    # LoggerAPIKey is the API key to use to send log events to the Honeycomb logging dataset
    # LoggerAPIKey: YOUR_API_KEY

    # LoggerDataset is the name of the dataset to which to send Refinery logs
    # LoggerDataset: refinery-logs

  # HoneycombMetrics is a section of the config only used if you are using the
  # HoneycombMetrics to send all metrics to a Honeycomb Dataset. If you are using a
  # different metrics service (eg prometheus) you can leave all this
  # commented out.
  # HoneycombMetrics:

    # MetricsHoneycombAPI is the URL for the upstream Honeycomb API.
    # MetricsHoneycombAPI: https://api.honeycomb.io

    # MetricsAPIKey is the API key to use to send log events to the Honeycomb logging dataset.
    # MetricsAPIKey: YOUR_API_KEY

    # MetricsDataset is the name of the dataset to which to send Refinery metrics
    # MetricsDataset: refinery-metrics

    # MetricsReportingInterval is the frequency (in seconds) to send metric events
    # to Honeycomb. Between 1 and 60 is recommended.
    # MetricsReportingInterval: 10


  PrometheusMetrics:
    # MetricsListenAddr determines the interface and port on which Prometheus will
    # listen for requests for /metrics.
    MetricsListenAddr: 0.0.0.0:9090


# Values used to build rules.yaml
# See the example in sample-configs/rules_complete.yaml for full details on all properties
rules:

  # DryRun - If enabled, marks traces that would be dropped given current sampling rules,
  # and sends all traces regardless
  # DryRun: false

  # This is the default sampler used.
  # Any traces received that are not for a defined dataset will use this sampler.
  # Deterministic Sampler implementation. This is the simplest sampling algorithm
  # - it is a static sample rate, choosing traces randomly to either keep or send
  # (at the appropriate rate). It is not influenced by the contents of the trace.
  Sampler: DeterministicSampler

  # SampleRate is the rate at which to sample. It indicates a ratio, where one
  # sample trace is kept for every n traces seen. For example, a SampleRate of 30
  # will keep 1 out of every 30 traces.
  SampleRate: 1

  ## Dataset sampling rules ##
  # Specify dataset rules by creating an object for each dataset
  # Note: If your dataset name contains a space, you will have to escape the dataset name
  # using single quotes, such as "dataset 1":
  #
  # This example creates a sampling definition for a dataset called: test-dataset
  # test-dataset:
    # Sampler: EMADynamicSampler
    # GoalSampleRate: 5
    # FieldList:
    #  - request.method
    #  - response.status_code

  # LiveReload - If disabled, triggers a rolling restart of the cluster whenever
  # the Rules configmap changes
  LiveReload: true

# Redis configuration
redis:

  # To install a simple single pod Redis deployment set this to true.
  # If false, you must specify a value for existingHost
  # For production, it is recommended to set this to false and provide
  # a highly available Redis configuration using redis.existingHost
  enabled: true

  # If redis.enabled is false this needs to be specified.
  # This needs to be the name:port of a Redis configuration
  # existingHost:

  # If redis.enabled is true, this the image that will be used to create
  # the Redis deployment
  image:
    repository: redis
    tag: 6.2.5
    pullPolicy: IfNotPresent

  # Node selector specific to installed Redis configuration. Requires redis.enabled to be true
  nodeSelector: {}

  # Tolerations specific to installed Redis configuration. Requires redis.enabled to be true
  tolerations: []

  # Affinity specific to installed Redis configuration. Requires redis.enabled to be true
  affinity: {}

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  labels: {}
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podLabels: {}

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: ClusterIP
  port: 80
  grpcPort: 4317
  labels: {}
  annotations: {}

ingress:
  enabled: false
  labels: {}
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: refinery.local
      path: /
  tls: []
  #  - secretName: refinery-tls
  #    hosts:
  #      - refinery.local

grpcIngress:
  enabled: false
  labels: {}
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: refinery.local
      path: /
  tls: []
  #  - secretName: refinery-tls
  #    hosts:
  #      - refinery.local


# Setup autoscaling for refinery
# When autoscaling events occur, trace sharding will be recomputed. This will result in traces with missing spans being
# sent to Honeycomb, for a small period of time (approximately config.TraceTimeout * 2).
# Because of this, scaleDown is disabled by default to avoid unnecessary broken traces should traffic go up and down rapidly.
autoscaling:
  enabled: false
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 75
  # targetMemoryUtilizationPercentage: 80
  behavior:
    scaleDown:
      selectPolicy: Disabled


nodeSelector: {}

tolerations: []

affinity: {}
