name: honeycomb-observability-pipeline

refinery:
  enabled: true
  image:
    repository: "honeycombio/refinery"
    tag: "2.9.3-htp-dev"
  config:
    Network:
      OpAMPEnabled: true
      OpAMPEndpoint: "ws://{{ include \"honeycomb-observability-pipeline.name\" . }}-observability-pipeline-beekeeper:4320/v1/opamp"
    PrometheusMetrics:
      Enabled: false
    OTelMetrics:
      Enabled: true
  environment:
    - name: REFINERY_HONEYCOMB_API_KEY
      valueFrom:
        secretKeyRef:
          name: honeycomb-observability-pipeline
          key: api-key

beekeeper:
  resources: {}
  serviceAccount:
    create: true
    name: ""
  image:
    repository: "honeycombio/beekeeper"
    pullPolicy: IfNotPresent
    tag: "latest"
  endpoint: https://api.honeycomb.io:443
  pipelineInstallationID: ""
  team: ""
  publicMgmtKey: ""
  persistentVolumeClaimName: ""
  defaultEnv:
    HONEYCOMB_MGMT_API_SECRET:
      content:
        valueFrom:
          secretKeyRef:
            name: honeycomb-observability-pipeline
            key: management-api-secret
    HONEYCOMB_API_KEY:
      content:
        valueFrom:
          secretKeyRef:
            name: honeycomb-observability-pipeline
            key: api-key
    TELEMETRY_ENDPOINT:
      enabled: true
      content:
        value: https://api.honeycomb.io:443
    TELEMETRY_KEY:
      enabled: true
      content:
        value: "${env:HONEYCOMB_API_KEY}"
    TELEMETRY_METRICS_DATASET:
      enabled: true
      content:
        value: collector-metrics
    LOG_LEVEL:
      enabled: true
      content:
        value: "info"
  extraEnvs: []
  volumes: []
  volumeMounts: []
  telemetry:
    enabled: false
    config:
      file_format: "0.3"
      resource:
        schema_url: https://opentelemetry.io/schemas/1.26.0
        attributes:
          - name: service.name
            value: "beekeeper"
          - name: service.version
            value: "0.0.1"
      propagator:
        composite:
          - tracecontext
          - baggage
      tracer_provider:
        processors:
          - batch:
              exporter:
                otlp:
                  protocol: http/protobuf
                  endpoint: http://{{ include "honeycomb-observability-pipeline.name" . }}-otelcol-deployment:4318
      logger_provider:
        processors:
          - batch:
              exporter:
                otlp:
                  protocol: http/protobuf
                  endpoint: http://{{ include "honeycomb-observability-pipeline.name" . }}-otelcol-deployment:4318

collector:
  enabled: true
  serviceAccount:
    create: true
    name: ""
  service:
    enabled: true
    ports:
      - name: otlp
        port: 4317
        targetPort: 4317
        protocol: TCP
        appProtocol: grpc
      - name: otlp-http
        port: 4318
        targetPort: 4318
        protocol: TCP
  resources: {}
  replicaCount: 2
  image:
    repository: ""
    pullPolicy: IfNotPresent
    tag: ""
  defaultEnv:
    HONEYCOMB_API_KEY:
      enabled: true
      content:
        valueFrom:
          secretKeyRef:
            name: honeycomb-observability-pipeline
            key: api-key
  extraEnvs: []
  volumes: []
  volumeMounts: []


otelcol-deployment:
  enabled: false
  mode: deployment
  image:
    repository: otel/opentelemetry-collector-k8s
  extraEnvs:
    - name: HONEYCOMB_API_KEY
      valueFrom:
        secretKeyRef:
          name: honeycomb-observability-pipeline
          key: api-key
  # We only want one of these collectors - any more and we'd produce duplicate data
  replicaCount: 1
  presets:
    # enables the k8sclusterreceiver and adds it to the metrics pipelines
    clusterMetrics:
      enabled: true
    # enables the k8sobjectsreceiver to collect events only and adds it to the logs pipelines
    kubernetesEvents:
      enabled: true
  config:
    receivers:
      jaeger: null
      prometheus: null
      zipkin: null
      otlp: null
      k8s_cluster:
        collection_interval: 30s
        metrics:
          # Disable replicaset metrics by default. These are typically high volume, low signal metrics.
          # If volume is not a concern, then the following blocks can be removed.
          k8s.replicaset.desired:
            enabled: false
          k8s.replicaset.available:
            enabled: false
    processors:
      transform/events:
        error_mode: ignore
        log_statements:
          - context: log
            statements:
              # adds a new watch-type attribute from the body if it exists
              - set(attributes["watch-type"], body["type"]) where IsMap(body) and body["type"] != nil

              # create new attributes from the body if the body is an object
              - merge_maps(attributes, body, "upsert") where IsMap(body) and body["object"] == nil
              - merge_maps(attributes, body["object"], "upsert") where IsMap(body) and body["object"] != nil

              # Transform the attributes so that the log events use the k8s.* semantic conventions
              - merge_maps(attributes, attributes[ "metadata"], "upsert") where IsMap(attributes[ "metadata"])
              - set(attributes["k8s.pod.name"], attributes["regarding"]["name"]) where attributes["regarding"]["kind"] == "Pod"
              - set(attributes["k8s.node.name"], attributes["regarding"]["name"]) where attributes["regarding"]["kind"] == "Node"
              - set(attributes["k8s.job.name"], attributes["regarding"]["name"]) where attributes["regarding"]["kind"] == "Job"
              - set(attributes["k8s.cronjob.name"], attributes["regarding"]["name"]) where attributes["regarding"]["kind"] == "CronJob"
              - set(attributes["k8s.namespace.name"], attributes["regarding"]["namespace"]) where attributes["regarding"]["kind"] == "Pod" or attributes["regarding"]["kind"] == "Job" or attributes["regarding"]["kind"] == "CronJob"

              # Transform the type attribtes into OpenTelemetry Severity types.
              - set(severity_text, attributes["type"]) where attributes["type"] == "Normal" or attributes["type"] == "Warning"
              - set(severity_number, SEVERITY_NUMBER_INFO) where attributes["type"] == "Normal"
              - set(severity_number, SEVERITY_NUMBER_WARN) where attributes["type"] == "Warning"
    exporters:
      otlp/k8s-metrics:
        endpoint: "api.honeycomb.io:443"
        # endpoint: "api.eu1.honeycomb.io:443" # EU instance
        headers:
          "x-honeycomb-team": "${env:HONEYCOMB_API_KEY}"
          "x-honeycomb-dataset": "k8s-metrics"
      otlp/k8s-events:
        endpoint: "api.honeycomb.io:443"
        # endpoint: "api.eu1.honeycomb.io:443" # EU instance
        headers:
          "x-honeycomb-team": "${env:HONEYCOMB_API_KEY}"
          "x-honeycomb-dataset": "k8s-events"
    service:
      telemetry:
        metrics:
          address: ""
          readers:
            - periodic:
                exporter:
                  otlp:
                    protocol: http/protobuf
                    endpoint: https://api.honeycomb.io:443
                    headers:
                      "x-honeycomb-team": ${env:HONEYCOMB_API_KEY}
      pipelines:
        traces: null
        metrics:
          receivers: [k8s_cluster]
          exporters: [otlp/k8s-metrics]
        logs:
          receivers: [k8sobjects]
          processors: [memory_limiter, transform/events, batch]
          exporters: [otlp/k8s-events]
  ports:
    jaeger-compact:
      enabled: false
    jaeger-thrift:
      enabled: false
    jaeger-grpc:
      enabled: false
    zipkin:
      enabled: false

otelcol-daemonset:
  enabled: false
  mode: daemonset
  image:
    repository: otel/opentelemetry-collector-k8s
  # Required to use the kubeletstats cpu/memory utilization metrics
  clusterRole:
    create: true
    rules:
      - apiGroups:
          - ""
        resources:
          - nodes/proxy
        verbs:
          - get
  extraEnvs:
    - name: HONEYCOMB_API_KEY
      valueFrom:
        secretKeyRef:
          name: honeycomb
          key: api-key
  service:
    enabled: true
    internalTrafficPolicy: Local
  presets:
    # enables the k8sattributesprocessor and adds it to the traces, metrics, and logs pipelines
    kubernetesAttributes:
      enabled: true
      extractAllPodLabels: true
      extractAllPodAnnotations: true
    # enables the kubeletstatsreceiver and adds it to the metrics pipelines
    kubeletMetrics:
      enabled: true
    logsCollection:
      enabled: true
  config:
    extensions:
      headers_setter:
        headers:
          - action: upsert
            key: x-honeycomb-dataset
            from_context: x-honeycomb-dataset
    receivers:
      jaeger: null
      prometheus: null
      zipkin: null
      otlp:
        protocols:
          http:
            include_metadata: true
      kubeletstats:
        # required as most clusters use self-signed certificates
        insecure_skip_verify: true
        collection_interval: 30s
        metric_groups:
          - node
          - pod
        metrics:
          k8s.node.uptime:
            enabled: true
          k8s.pod.uptime:
            enabled: true
          k8s.pod.cpu_limit_utilization:
            enabled: true
          k8s.pod.cpu_request_utilization:
            enabled: true
          k8s.pod.memory_limit_utilization:
            enabled: true
          k8s.pod.memory_request_utilization:
            enabled: true
          k8s.node.cpu.usage:
            enabled: true
          k8s.pod.cpu.usage:
            enabled: true
          container.cpu.usage:
            enabled: true
          k8s.node.cpu.utilization:
            enabled: false
          k8s.pod.cpu.utilization:
            enabled: false
          container.cpu.utilization:
            enabled: false
    processors:
      batch:
        metadata_keys:
          - x-honeycomb-dataset
    exporters:
      otlp:
        endpoint: "api.honeycomb.io:443"
        # endpoint: "api.eu1.honeycomb.io:443" # EU instance
        auth:
          authenticator: headers_setter
        headers:
          "x-honeycomb-team": "${env:HONEYCOMB_API_KEY}"
      otlp/refinery:
        endpoint: '{{ include "honeycomb-observability-pipeline.name" . }}-refinery:4317'
        headers:
          "x-honeycomb-team": "${env:HONEYCOMB_API_KEY}"
        tls:
          insecure: true
      otlp/k8s-metrics:
        endpoint: "api.honeycomb.io:443"
        # endpoint: "api.eu1.honeycomb.io:443" # EU instance
        headers:
          "x-honeycomb-team": "${env:HONEYCOMB_API_KEY}"
          "x-honeycomb-dataset": "k8s-metrics"
      otlp/k8s-logs:
        endpoint: "api.honeycomb.io:443"
        # endpoint: "api.eu1.honeycomb.io:443" # EU instance
        headers:
          "x-honeycomb-team": "${env:HONEYCOMB_API_KEY}"
          "x-honeycomb-dataset": "k8s-logs"
    service:
      telemetry:
        metrics:
          address: ""
          readers:
            - periodic:
                exporter:
                  otlp:
                    protocol: http/protobuf
                    endpoint: https://api.honeycomb.io:443
                    headers:
                      "x-honeycomb-team": ${env:HONEYCOMB_API_KEY}
      extensions: [health_check, headers_setter]
      pipelines:
        traces:
          receivers: [otlp]
          exporters: [otlp/refinery]
        metrics/otlp:
          receivers: [otlp]
          processors: [memory_limiter, k8sattributes, batch]
          exporters: [otlp]
        logs/otlp:
          receivers: [otlp]
          processors: [memory_limiter, k8sattributes, batch]
          exporters: [otlp]
        metrics:
          receivers: [kubeletstats]
          exporters: [otlp/k8s-metrics]
        logs:
          exporters: [otlp/k8s-logs]
  ports:
    jaeger-compact:
      enabled: false
    jaeger-thrift:
      enabled: false
    jaeger-grpc:
      enabled: false
    zipkin:
      enabled: false
